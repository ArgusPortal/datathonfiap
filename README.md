# Datathon FIAP - Modelo de Risco de Defasagem Escolar

**Projeto**: PrediÃ§Ã£o de risco de defasagem escolar para estudantes da AssociaÃ§Ã£o Passos MÃ¡gicos  
**PerÃ­odo**: 2022â€“2024  
**Status**: Fase 4 (MVP OperÃ¡vel) âœ…

---

## VisÃ£o Geral

Modelo de Machine Learning para identificar estudantes em risco de defasagem escolar (moderada ou severa) usando dados histÃ³ricos do programa Passos MÃ¡gicos. O score permite intervenÃ§Ã£o preventiva antes da defasagem se consolidar.

**Target**: prediÃ§Ã£o binÃ¡ria t â†’ t+1 (usar dados do ano t para predizer risco no ano t+1)  
**MÃ©trica principal**: Recall da classe positiva â‰¥ 0.75  
**PopulaÃ§Ã£o**: Fases 0â€“7 do programa  
**Modelo Atual**: Random Forest calibrado (v1.1.0), threshold otimizado 0.040

---

## Quickstart

### 1. Setup do Ambiente

```bash
# Clonar repositÃ³rio
git clone {{REPO_URL}}
cd datathonfiap

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Preparar Dados

```bash
# Colocar arquivo de dados em data/
# Estrutura esperada: data/raw/PEDE_PASSOS_DATASET_FIAP.csv
# Schema: ver docs/data_contract.md
```

### 3. Executar Pipeline de Dados

```bash
# Processar dados brutos
python -m src.make_dataset

# SaÃ­das:
# - data/processed/dataset_train_2023.parquet
# - data/processed/dataset_val_2024.parquet
```

### 4. Treinar Modelo

```bash
# Treinar modelo v1 (com mÃºltiplos candidatos)
python -m src.train --config configs/train_v1.yaml

# Artefatos gerados em artifacts/:
# - model_v1.joblib
# - model_metadata_v1.json
# - model_signature_v1.json
# - model_report_v1.md
```

### 5. Executar API

```bash
# Desenvolvimento
uvicorn app.main:app --reload --port 8000

# ProduÃ§Ã£o
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Acessar: http://localhost:8000/docs (Swagger UI)

### 6. Deploy com Docker

```bash
# Build da imagem
docker build -t datathon-api:v1 .

# Executar container
docker run -d -p 8000:8000 --name datathon-api datathon-api:v1

# Verificar logs
docker logs -f datathon-api

# Verificar saÃºde
curl http://localhost:8000/health
```

### 7. Rodar Testes

```bash
# Todos os testes com cobertura
pytest --cov=src --cov=app --cov-report=html

# Apenas testes rÃ¡pidos (sem integraÃ§Ã£o)
pytest tests/ -k "not integration" --tb=short

# Verificar cobertura mÃ­nima
pytest --cov-fail-under=80
```

RelatÃ³rio de cobertura: `htmlcov/index.html`

---

## Estrutura do Projeto

```
datathonfiap/
â”œâ”€â”€ app/                    # API FastAPI
â”‚   â”œâ”€â”€ main.py            # Endpoints (health, metadata, predict)
â”‚   â”œâ”€â”€ config.py          # ConfiguraÃ§Ãµes de ambiente
â”‚   â”œâ”€â”€ logging_config.py  # Logging estruturado JSON
â”‚   â”œâ”€â”€ model_loader.py    # Carregamento de modelo
â”‚   â”œâ”€â”€ drift_store.py     # Monitoramento de drift
â”‚   â””â”€â”€ schema.py          # Schemas Pydantic
â”œâ”€â”€ src/                   # CÃ³digo-fonte do pipeline
â”‚   â”œâ”€â”€ config.py          # ConfiguraÃ§Ãµes globais
â”‚   â”œâ”€â”€ make_dataset.py    # Pipeline de dados
â”‚   â”œâ”€â”€ data_quality.py    # Checks de qualidade
â”‚   â”œâ”€â”€ preprocessing.py   # Limpeza e transformaÃ§Ã£o
â”‚   â”œâ”€â”€ feature_engineering.py  # CriaÃ§Ã£o de features
â”‚   â”œâ”€â”€ train.py           # Treino do modelo
â”‚   â”œâ”€â”€ evaluate.py        # AvaliaÃ§Ã£o e mÃ©tricas
â”‚   â”œâ”€â”€ model_card.py      # GeraÃ§Ã£o de model card
â”‚   â””â”€â”€ utils.py           # UtilitÃ¡rios
â”œâ”€â”€ tests/                 # Testes automatizados (156 testes, 85% coverage)
â”‚   â”œâ”€â”€ test_smoke.py      # Testes de smoke bÃ¡sicos
â”‚   â”œâ”€â”€ test_api_integration.py  # Testes de integraÃ§Ã£o da API
â”‚   â”œâ”€â”€ test_model_loader.py     # Testes do carregador de modelo
â”‚   â”œâ”€â”€ test_drift_store.py      # Testes de drift monitoring
â”‚   â”œâ”€â”€ test_schema.py           # Testes de validaÃ§Ã£o
â”‚   â”œâ”€â”€ test_logging.py          # Testes de logging
â”‚   â””â”€â”€ ...
â”œâ”€â”€ artifacts/             # Artefatos do modelo
â”‚   â”œâ”€â”€ model_v1.joblib    # Modelo serializado
â”‚   â”œâ”€â”€ model_metadata_v1.json  # Metadata (versÃ£o, threshold, mÃ©tricas)
â”‚   â”œâ”€â”€ model_signature_v1.json # Assinatura de features
â”‚   â””â”€â”€ model_report_v1.md      # RelatÃ³rio de avaliaÃ§Ã£o
â”œâ”€â”€ data/                  # Datasets (nÃ£o versionado)
â”‚   â”œâ”€â”€ raw/              # Dados originais
â”‚   â”œâ”€â”€ processed/        # Dados processados
â”‚   â””â”€â”€ reports/          # RelatÃ³rios de qualidade
â”œâ”€â”€ logs/                  # Logs de execuÃ§Ã£o
â”‚   â””â”€â”€ drift_events.jsonl # Eventos de drift (sem PII)
â”œâ”€â”€ docs/                  # DocumentaÃ§Ã£o tÃ©cnica
â”œâ”€â”€ notebooks/             # Jupyter notebooks para EDA
â”œâ”€â”€ Dockerfile            # ContainerizaÃ§Ã£o
â”œâ”€â”€ .dockerignore         # ExclusÃµes do Docker
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â””â”€â”€ pytest.ini            # ConfiguraÃ§Ã£o pytest
```

---

## API Endpoints

### `GET /health`

Verifica status da API e modelo carregado.

**Response** (200):
```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "v1.1.0"
}
```

### `GET /metadata`

Retorna metadata do modelo (sem informaÃ§Ãµes sensÃ­veis).

**Response** (200):
```json
{
  "model_version": "v1.1.0",
  "threshold": 0.040221,
  "expected_features": ["fase_2023", "iaa_2023", "ian_2023", ...],
  "feature_count": 15
}
```

### `POST /predict`

Prediz risco de defasagem escolar para um ou mais estudantes.

**Request**:
```json
{
  "instances": [
    {
      "fase_2023": 3.0,
      "iaa_2023": 6.5,
      "ian_2023": 7.2,
      "ida_2023": 5.8,
      "idade_2023": 14,
      "ieg_2023": 6.0,
      "instituicao_2023": 1,
      "ipp_2023": 7.5,
      "ips_2023": 8.0,
      "ipv_2023": 6.2,
      "max_indicador": 8.0,
      "media_indicadores": 6.8,
      "min_indicador": 5.0,
      "range_indicadores": 3.0,
      "std_indicadores": 0.9
    }
  ]
}
```

**Response** (200):
```json
{
  "predictions": [
    {
      "risk_score": 0.72,
      "risk_label": 1,
      "threshold_used": 0.040221
    }
  ],
  "model_version": "v1.1.0",
  "processing_time_ms": 12.5,
  "request_id": "abc123"
}
```

**Notas**:
- `risk_score`: probabilidade de defasagem (0.0 a 1.0)
- `risk_label`: 1 = em risco, 0 = sem risco (baseado no threshold)
- Campos de ID (ra, nome, student_id) sÃ£o ignorados automaticamente
- MÃ¡ximo 1000 instÃ¢ncias por request

---

## ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

| VariÃ¡vel | Default | DescriÃ§Ã£o |
|----------|---------|-----------|
| `MODEL_PATH` | `artifacts/model_v1.joblib` | Caminho do modelo |
| `METADATA_PATH` | `artifacts/model_metadata_v1.json` | Caminho dos metadados |
| `SIGNATURE_PATH` | `artifacts/model_signature_v1.json` | Caminho da assinatura |
| `PORT` | `8000` | Porta da API |
| `LOG_LEVEL` | `INFO` | NÃ­vel de logging |
| `DEFAULT_THRESHOLD` | `0.040` | Threshold padrÃ£o |
| `EXTRA_FEATURE_POLICY` | `reject` | PolÃ­tica para features extras |
| `DRIFT_LOG_PATH` | `logs/drift_events.jsonl` | Caminho do log de drift |

### Exemplo .env

```bash
MODEL_PATH=artifacts/model_v1.joblib
METADATA_PATH=artifacts/model_metadata_v1.json
LOG_LEVEL=DEBUG
PORT=8080
```

---

## Docker

### Build

```bash
docker build -t datathon-api:v1 .
```

### Run

```bash
# Modo bÃ¡sico
docker run -p 8000:8000 datathon-api:v1

# Com variÃ¡veis de ambiente
docker run -p 8000:8000 \
  -e LOG_LEVEL=DEBUG \
  -e DEFAULT_THRESHOLD=0.05 \
  datathon-api:v1

# Com volume para logs persistentes
docker run -p 8000:8000 \
  -v $(pwd)/logs:/app/logs \
  datathon-api:v1
```

### Health Check

O container inclui health check automÃ¡tico:
```bash
curl http://localhost:8000/health
```

### Docker Compose (exemplo)

```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

---

## Logging e Monitoramento

### Formato de Logs

Logs estruturados em JSON para fÃ¡cil ingestÃ£o:

```json
{
  "timestamp": "2026-01-15T10:30:00Z",
  "level": "INFO",
  "logger": "app.main",
  "message": "Prediction request completed",
  "request_id": "abc123",
  "processing_time_ms": 12.5,
  "batch_size": 1
}
```

### Drift Monitoring

Eventos de drift sÃ£o registrados em `logs/drift_events.jsonl` sem PII:

```json
{
  "timestamp": "2026-01-15T10:30:00Z",
  "event_type": "batch_prediction",
  "batch_size": 10,
  "prediction_summary": {
    "mean_score": 0.45,
    "positive_rate": 0.30
  },
  "feature_stats": {
    "fase_2023": {"mean": 3.2, "std": 1.1}
  }
}
```

---

## Comandos Principais

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| `python -m src.make_dataset` | Processar dados brutos |
| `python -m src.train` | Treinar modelo |
| `uvicorn app.main:app --reload` | API (desenvolvimento) |
| `pytest --cov` | Rodar testes com cobertura |
| `docker build -t datathon-api .` | Build Docker image |
| `docker run -p 8000:8000 datathon-api` | Run container |

---

## DocumentaÃ§Ã£o TÃ©cnica

- **[Product Brief](docs/product_brief.md)**: contexto, objetivo, critÃ©rios de sucesso
- **[Decision Log](docs/decision_log.md)**: decisÃµes tÃ©cnicas (target, horizonte, mÃ©trica, populaÃ§Ã£o)
- **[Data Contract](docs/data_contract.md)**: schema, features, regras de qualidade, leakage watchlist
- **[Model Report](artifacts/model_report_v1.md)**: mÃ©tricas, comparaÃ§Ã£o de modelos, anÃ¡lise de calibraÃ§Ã£o

---

## MÃ©tricas do Modelo (v1.1.0)

| MÃ©trica | Valor |
|---------|-------|
| Recall (classe 1) | 0.75+ |
| Precision (classe 1) | ~0.40 |
| ROC-AUC | ~0.80 |
| Brier Score | ~0.15 |
| Threshold Otimizado | 0.040 |

**Modelo**: Random Forest (100 trees) + CalibraÃ§Ã£o Sigmoid  
**Features**: 15 indicadores educacionais e compostos

---

## Roadmap

### âœ… Fase 0: DiagnÃ³stico
- [x] Product Brief
- [x] Decision Log
- [x] Data Contract
- [x] Skeleton do repo

### âœ… Fase 1: EDA e Limpeza
- [x] Pipeline de dados (`make_dataset.py`)
- [x] Checks de qualidade (`data_quality.py`)
- [x] ValidaÃ§Ã£o anti-vazamento

### âœ… Fase 2: Feature Engineering
- [x] Features compostas (agregaÃ§Ãµes de indicadores)
- [x] NormalizaÃ§Ã£o de colunas
- [x] ValidaÃ§Ã£o de features por ano

### âœ… Fase 3: Modelagem
- [x] Baseline models (LogReg, HistGB, RF)
- [x] CalibraÃ§Ã£o de probabilidades
- [x] SeleÃ§Ã£o de threshold com constraints
- [x] Model card automÃ¡tico

### âœ… Fase 4: MVP OperÃ¡vel
- [x] API FastAPI com endpoints completos
- [x] Docker containerizaÃ§Ã£o
- [x] Logging estruturado (JSON)
- [x] Drift monitoring (sem PII)
- [x] Testes 85%+ coverage (156 testes)
- [x] DocumentaÃ§Ã£o atualizada

### ðŸ”œ Fase 5: ProduÃ§Ã£o
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Monitoring dashboard
- [ ] A/B testing framework
- [ ] Fairness analysis por grupos

---

## Desenvolvimento

### Adicionar Nova Feature

1. Implementar em `src/feature_engineering.py`
2. Atualizar `docs/data_contract.md`
3. Adicionar testes em `tests/test_feature_engineering.py`
4. Validar nÃ£o-vazamento na Leakage Watchlist
5. Re-treinar modelo

### Atualizar Modelo

1. Modificar `src/train.py`
2. Re-treinar: `python -m src.train`
3. Verificar mÃ©tricas em `artifacts/model_report_v1.md`
4. Atualizar versÃ£o em metadata
5. Rebuild Docker image

---

## Contato e Suporte

**Equipe**: {{NOME_EQUIPE}}  
**RepositÃ³rio**: {{REPO_URL}}  
**Stakeholder**: AssociaÃ§Ã£o Passos MÃ¡gicos  
**Datathon**: FIAP 2026

---

## LicenÃ§a

{{TODO: definir licenÃ§a apropriada com stakeholders}}
