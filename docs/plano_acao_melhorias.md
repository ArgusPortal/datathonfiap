# üìã Plano de A√ß√£o - Melhorias no Pipeline de ML

**Projeto:** Predi√ß√£o de Risco de Defasagem Escolar - Passos M√°gicos  
**Data:** 15/01/2026  
**Autor:** Argus Portal  
**Status:** Planejamento

---

## üìä Resumo Executivo

Este plano endere√ßa **8 problemas identificados** no pipeline atual, organizados em **4 fases** de implementa√ß√£o. O objetivo √© aumentar a robustez do pr√©-processamento, recuperar features perdidas, e melhorar a qualidade do modelo.

### M√©tricas de Sucesso
- [ ] Zero features corrompidas no dataset final
- [ ] Recuperar features: `g√™nero`, `idade` (num√©rica), deltas temporais
- [ ] Reduzir missing imputado sem an√°lise
- [ ] Manter ou melhorar Recall ‚â• 75% com PR-AUC ‚â• 0.85

---

## üî¥ FASE 1: Corre√ß√µes Cr√≠ticas (Prioridade Alta)

### 1.1 Corrigir Coluna `idade` Corrompida

**Problema:** Valores como `'1900-01-07'` s√£o datas serializadas do Excel que deveriam ser n√∫meros (7, 8, etc.)

**Arquivo:** `src/make_dataset.py`

**A√ß√£o:**
```python
def fix_excel_date_as_number(value):
    """
    Corrige valores de idade que foram interpretados como datas pelo Excel.
    Excel serializa datas como dias desde 1900-01-01.
    Ent√£o '1900-01-07' = dia 7 = idade 7.
    """
    if pd.isna(value):
        return None
    
    # Se j√° √© n√∫mero, retorna
    if isinstance(value, (int, float)):
        return int(value) if not pd.isna(value) else None
    
    # Se √© string num√©rica
    try:
        return int(float(value))
    except (ValueError, TypeError):
        pass
    
    # Se √© data serializada do Excel (1900-01-XX)
    if isinstance(value, str) and value.startswith('1900-01-'):
        try:
            day = int(value.split('-')[-1])
            if 5 <= day <= 25:  # Range v√°lido de idade
                return day
        except:
            pass
    
    # Tenta parse de data
    try:
        from datetime import datetime
        dt = datetime.strptime(value, '%Y-%m-%d')
        # Se ano √© 1900, √© serializa√ß√£o do Excel
        if dt.year == 1900:
            return dt.day
    except:
        pass
    
    return None
```

**Aplicar em:** `load_and_normalize_sheet()` ap√≥s carregar o DataFrame

**Teste:**
```python
def test_fix_excel_date_as_number():
    assert fix_excel_date_as_number('8') == 8
    assert fix_excel_date_as_number('1900-01-07') == 7
    assert fix_excel_date_as_number(10) == 10
    assert fix_excel_date_as_number('1900-01-15') == 15
```

---

### 1.2 Normalizar Acentos no Mapeamento de Colunas

**Problema:** Coluna `g√™nero` n√£o √© mapeada para `genero` porque acentos n√£o s√£o normalizados.

**Arquivo:** `src/make_dataset.py`

**A√ß√£o:**
```python
import unicodedata

def normalize_column_name(col: str) -> str:
    """Normaliza nome de coluna removendo acentos e padronizando."""
    # Remove acentos
    col_clean = unicodedata.normalize('NFKD', col)
    col_clean = ''.join(c for c in col_clean if not unicodedata.combining(c))
    
    # Lowercase e strip
    col_clean = col_clean.lower().strip()
    
    # Remove caracteres especiais
    col_clean = col_clean.replace('_', ' ')
    
    # Busca no mapeamento
    if col_clean in COLUMN_MAPPING:
        return COLUMN_MAPPING[col_clean]
    
    return col_clean.replace(' ', '_')
```

**Adicionar ao mapeamento:**
```python
COLUMN_MAPPING = {
    ...
    'genero': 'genero',
    'g√™nero': 'genero',  # Com acento
    'sexo': 'genero',
}
```

---

### 1.3 Incluir `genero` nas Features Permitidas

**Arquivo:** `src/make_dataset.py`

**A√ß√£o:** Verificar que `genero` est√° em `ALLOWED_FEATURE_COLUMNS`:
```python
ALLOWED_FEATURE_COLUMNS = [
    'ra', 'nome', 'instituicao', 'idade', 'genero',  # ‚úÖ j√° est√°
    'fase', 'anos_pm', 'bolsista',
    'inde', 'ian', 'ida', 'ieg', 'iaa', 'ips', 'ipp', 'ipv', 'ipm',
    'indicador_nutricional',
]
```

---

## üü† FASE 2: Melhorias no Pr√©-processamento (Prioridade M√©dia)

### 2.1 Normalizar Categorias de Institui√ß√£o

**Problema:** Duplicatas por case (`Privada - Programa de Apadrinhamento` vs `apadrinhamento`)

**Arquivo:** `src/make_dataset.py` (nova fun√ß√£o)

**A√ß√£o:**
```python
def normalize_instituicao(value: str) -> str:
    """Normaliza valores da coluna institui√ß√£o."""
    if pd.isna(value):
        return 'Desconhecido'
    
    value = str(value).strip().lower()
    
    # Mapeamento para categorias padronizadas
    if 'p√∫blica' in value or 'publica' in value:
        return 'Publica'
    elif 'apadrinhamento' in value:
        return 'Privada_Apadrinhamento'
    elif 'bolsa' in value or 'parceira' in value:
        return 'Privada_Bolsa'
    elif 'privada' in value:
        return 'Privada'
    elif 'concluiu' in value or '3¬∫ em' in value:
        return 'Concluiu_EM'
    else:
        return 'Outro'
```

**Aplicar ap√≥s normaliza√ß√£o de colunas.**

---

### 2.2 Criar Features Indicadoras de Missing

**Problema:** Missing pode ser informativo (MNAR) - aluno sem nota pode indicar problema.

**Arquivo:** `src/feature_engineering.py`

**A√ß√£o:**
```python
def create_missing_indicators(df: pd.DataFrame, 
                              columns: List[str] = None) -> pd.DataFrame:
    """
    Cria features bin√°rias indicando valores ausentes.
    
    √ötil quando missing √© informativo (ex: aluno sem nota em IDA 
    pode indicar que n√£o fez avalia√ß√£o).
    """
    df = df.copy()
    
    if columns is None:
        # Indicadores num√©ricos que podem ter missing informativo
        columns = ['ida', 'ieg', 'iaa', 'ips', 'ipp', 'ipv']
    
    indicators_created = []
    for col in columns:
        # Busca coluna com sufixo de ano
        matching = [c for c in df.columns if c.startswith(col)]
        for match_col in matching:
            if df[match_col].isna().sum() > 0:
                indicator_name = f"{match_col}_missing"
                df[indicator_name] = df[match_col].isna().astype(int)
                indicators_created.append(indicator_name)
    
    if indicators_created:
        logger.info(f"Missing indicators criados: {indicators_created}")
    
    return df
```

---

### 2.3 Criar Deltas Temporais (22‚Üí23)

**Problema:** C√≥digo atual falha por inconsist√™ncia de sufixos (`_22` vs `_2022`)

**Arquivo:** `src/feature_engineering.py`

**A√ß√£o:** Corrigir `create_delta_features()`:
```python
def create_delta_features(df: pd.DataFrame) -> pd.DataFrame:
    """Cria features de delta com busca flex√≠vel de sufixos."""
    df = df.copy()
    deltas_created = []
    
    for prefix in INDICATOR_PREFIXES:
        # Busca mais flex√≠vel
        col_22 = None
        col_23 = None
        
        for c in df.columns:
            c_lower = c.lower()
            if c_lower.startswith(prefix):
                if '_22' in c_lower or '_2022' in c_lower or c_lower.endswith('_22'):
                    col_22 = c
                elif '_23' in c_lower or '_2023' in c_lower or c_lower.endswith('_23'):
                    col_23 = c
        
        if col_22 and col_23:
            # Verifica se s√£o num√©ricas
            if (pd.api.types.is_numeric_dtype(df[col_22]) and 
                pd.api.types.is_numeric_dtype(df[col_23])):
                delta_col = f"delta_{prefix}_22_23"
                df[delta_col] = df[col_23] - df[col_22]
                deltas_created.append(delta_col)
    
    if deltas_created:
        logger.info(f"Deltas criados: {deltas_created}")
    
    return df
```

---

### 2.4 Analisar Vi√©s nos Dados Perdidos

**Problema:** 249 alunos de 2023 n√£o t√™m match em 2024 - pode haver vi√©s.

**Arquivo:** Novo script `src/analyze_data_loss.py`

**A√ß√£o:**
```python
def analyze_unmatched_students(df_2023: pd.DataFrame, 
                                df_2024: pd.DataFrame) -> Dict:
    """
    Analisa caracter√≠sticas dos alunos que n√£o persistiram para 2024.
    Identifica se h√° vi√©s sistem√°tico na perda de dados.
    """
    matched_ras = set(df_2023['ra']) & set(df_2024['ra'])
    
    df_matched = df_2023[df_2023['ra'].isin(matched_ras)]
    df_unmatched = df_2023[~df_2023['ra'].isin(matched_ras)]
    
    analysis = {
        'n_matched': len(df_matched),
        'n_unmatched': len(df_unmatched),
        'pct_lost': len(df_unmatched) / len(df_2023) * 100,
    }
    
    # Compara distribui√ß√µes de indicadores
    indicators = ['ian', 'ida', 'ieg', 'iaa', 'ips', 'ipp', 'ipv']
    for ind in indicators:
        if ind in df_2023.columns:
            analysis[f'{ind}_mean_matched'] = df_matched[ind].mean()
            analysis[f'{ind}_mean_unmatched'] = df_unmatched[ind].mean()
            # T-test para diferen√ßa significativa
            from scipy import stats
            stat, pvalue = stats.ttest_ind(
                df_matched[ind].dropna(), 
                df_unmatched[ind].dropna()
            )
            analysis[f'{ind}_pvalue'] = pvalue
    
    return analysis
```

**Documentar no data_card.json o resultado dessa an√°lise.**

---

## üü° FASE 3: Melhorias no Treinamento (Prioridade M√©dia-Baixa)

### 3.1 Adicionar Feature de Tempo na Institui√ß√£o

**Arquivo:** `src/feature_engineering.py`

**A√ß√£o:**
```python
def create_tenure_feature(df: pd.DataFrame, 
                          reference_year: int = 2023) -> pd.DataFrame:
    """Cria feature de anos na institui√ß√£o Passos M√°gicos."""
    df = df.copy()
    
    if 'ano_ingresso' in df.columns:
        col_name = f'anos_pm_{reference_year}'
        df[col_name] = reference_year - df['ano_ingresso']
        # Limita a valores razo√°veis
        df[col_name] = df[col_name].clip(lower=0, upper=15)
        logger.info(f"Feature criada: {col_name}")
    
    return df
```

---

### 3.2 Considerar Target Multi-classe ou Ordinal

**Problema:** Target bin√°rio perde granularidade (defasagem -1 vs -3)

**Arquivo:** `src/make_dataset.py`

**A√ß√£o:** Criar op√ß√£o para target multi-classe:
```python
def compute_target(defasagem: pd.Series, 
                   mode: str = 'binary') -> pd.Series:
    """
    Computa target baseado na defasagem.
    
    Args:
        defasagem: S√©rie com valores de defasagem
        mode: 'binary' (0/1), 'multiclass' (0,1,2,3), 'ordinal' (-3 a +3)
    """
    if mode == 'binary':
        return (defasagem < 0).astype(int)
    
    elif mode == 'multiclass':
        # 0=sem risco, 1=risco leve, 2=risco moderado, 3=risco alto
        return pd.cut(defasagem, 
                      bins=[-np.inf, -2, -1, 0, np.inf],
                      labels=[3, 2, 1, 0]).astype(int)
    
    elif mode == 'ordinal':
        return defasagem.astype(int)
    
    else:
        raise ValueError(f"Mode inv√°lido: {mode}")
```

**Nota:** Para MVP, manter bin√°rio. Multi-classe para vers√£o futura.

---

### 3.3 Validar Correla√ß√£o Missing vs Target

**Arquivo:** `src/data_quality.py`

**A√ß√£o:**
```python
def check_missing_target_correlation(df: pd.DataFrame, 
                                     target_col: str,
                                     threshold: float = 0.1) -> QualityCheckResult:
    """
    Verifica se missing est√° correlacionado com target (potencial vi√©s).
    """
    issues = []
    
    for col in df.columns:
        if col == target_col:
            continue
        
        missing_mask = df[col].isna()
        if missing_mask.sum() > 0:
            # Taxa de target=1 entre missing vs n√£o-missing
            rate_missing = df.loc[missing_mask, target_col].mean()
            rate_present = df.loc[~missing_mask, target_col].mean()
            diff = abs(rate_missing - rate_present)
            
            if diff > threshold:
                issues.append({
                    'column': col,
                    'target_rate_when_missing': rate_missing,
                    'target_rate_when_present': rate_present,
                    'difference': diff
                })
    
    passed = len(issues) == 0
    return QualityCheckResult(
        check_name='missing_target_correlation',
        passed=passed,
        message=f"{'Sem' if passed else len(issues)} correla√ß√µes missing-target detectadas",
        details={'issues': issues}
    )
```

---

## üîµ FASE 4: Documenta√ß√£o e Testes (Cont√≠nuo)

### 4.1 Atualizar Testes Unit√°rios

**Arquivos:** `tests/test_preprocessing.py`, `tests/test_make_dataset.py`

**Novos testes necess√°rios:**
```python
# test_preprocessing.py
def test_fix_excel_date_idade():
    """Testa corre√ß√£o de idade corrompida pelo Excel."""
    
def test_normalize_column_removes_accents():
    """Testa que g√™nero ‚Üí genero."""
    
def test_normalize_instituicao():
    """Testa padroniza√ß√£o de categorias."""

# test_feature_engineering.py
def test_create_missing_indicators():
    """Testa cria√ß√£o de features de missing."""
    
def test_create_delta_features_flexible_suffix():
    """Testa deltas com sufixos _22 e _2022."""
    
def test_create_tenure_feature():
    """Testa c√°lculo de anos_pm."""
```

---

### 4.2 Atualizar Data Card

**Arquivo:** `data/processed/data_card.json`

**Adicionar se√ß√µes:**
```json
{
  "preprocessing_fixes": {
    "idade_corruption_fixed": true,
    "genero_recovered": true,
    "instituicao_normalized": true
  },
  "feature_engineering": {
    "missing_indicators": ["ida_2023_missing", ...],
    "deltas_created": ["delta_inde_22_23", ...],
    "tenure_feature": "anos_pm_2023"
  },
  "data_loss_analysis": {
    "students_2023": 1014,
    "students_matched": 765,
    "pct_lost": 24.5,
    "bias_detected": false
  }
}
```

---

## üìÖ Cronograma Sugerido

| Fase | Tarefa | Esfor√ßo | Depend√™ncia |
|------|--------|---------|-------------|
| 1.1 | Fix idade corrompida | 2h | - |
| 1.2 | Normalizar acentos | 1h | - |
| 1.3 | Incluir g√™nero | 0.5h | 1.2 |
| 2.1 | Normalizar institui√ß√£o | 1h | - |
| 2.2 | Missing indicators | 2h | - |
| 2.3 | Deltas temporais | 1h | - |
| 2.4 | An√°lise vi√©s dados perdidos | 2h | - |
| 3.1 | Feature tempo institui√ß√£o | 1h | - |
| 3.2 | Target multi-classe | 2h | - |
| 3.3 | Correla√ß√£o missing-target | 1h | - |
| 4.1 | Testes unit√°rios | 3h | 1.x, 2.x |
| 4.2 | Atualizar data card | 1h | 1.x, 2.x |

**Total estimado:** ~17 horas

---

## ‚úÖ Checklist de Valida√ß√£o

Ap√≥s implementar as melhorias:

- [ ] `idade_2023` √© `int64` com valores entre 5-25
- [ ] `genero_2023` existe no dataset final
- [ ] `instituicao_2023` tem ‚â§5 categorias padronizadas
- [ ] Features `*_missing` criadas para indicadores com >5% missing
- [ ] Deltas `delta_*_22_23` criados para INDE e indicadores
- [ ] Data card documenta todas as transforma√ß√µes
- [ ] Todos os testes passando (`pytest tests/ -v`)
- [ ] Coverage ‚â• 80%
- [ ] Recall do modelo ‚â• 75%
- [ ] Nenhum warning de tipo no treinamento

---

## üöÄ Ordem de Execu√ß√£o Recomendada

1. **Primeiro:** Fase 1 (corre√ß√µes cr√≠ticas) - impacto imediato
2. **Segundo:** Fase 4.1 (testes) - para garantir n√£o-regress√£o
3. **Terceiro:** Fase 2 (melhorias pr√©-processamento)
4. **Quarto:** Re-treinar modelo e comparar m√©tricas
5. **Quinto:** Fase 3 (melhorias opcionais) baseado nos resultados
6. **√öltimo:** Fase 4.2 (documenta√ß√£o)

---

## üìù Notas Adicionais

### Decis√µes de Design

1. **Por que n√£o usar One-Hot Encoding no `make_dataset.py`?**
   - Mantemos categ√≥ricas como strings no parquet para flexibilidade
   - Encoding √© feito no pipeline sklearn (ColumnTransformer)
   - Permite diferentes estrat√©gias de encoding por modelo

2. **Por que manter target bin√°rio no MVP?**
   - Simplifica m√©tricas e interpreta√ß√£o
   - Recall de 100% j√° atinge objetivo de "n√£o perder nenhum aluno"
   - Multi-classe pode ser explorado em vers√£o futura

3. **Threshold de missing indicators (5%)?**
   - Abaixo de 5%, impacto √© m√≠nimo
   - Acima, pode haver padr√£o informativo
   - Ajust√°vel via configura√ß√£o

### Riscos

| Risco | Mitiga√ß√£o |
|-------|-----------|
| Perda de performance ap√≥s mudan√ßas | Baseline metrics documentadas, testes A/B |
| Overfitting com mais features | Cross-validation, regulariza√ß√£o |
| Breaking changes em produ√ß√£o | Feature flags, versionamento |

---

*Documento gerado em: 15/01/2026*  
*Pr√≥xima revis√£o: Ap√≥s implementa√ß√£o da Fase 1*
